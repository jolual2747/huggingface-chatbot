{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bot import get_chroma_db, load_documents\n",
    "from utils import DocsJSONLLoader, get_openai_api_key, get_file_path\n",
    "from langchain_openai import OpenAIEmbeddings, OpenAI\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, RetrievalQA, StuffDocumentsChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "OPENAI_API_KEY = \n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando embeddings\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model = \"text-embedding-ada-002\")\n",
    "documents = load_documents(get_file_path())\n",
    "print(\"Cargando embeddings\")\n",
    "vector_store = get_chroma_db(\n",
    "    embeddings,\n",
    "    documents,\n",
    "    \"../chroma_docs\"\n",
    ")\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_kwargs = {\"k\":3}\n",
    ")\n",
    "llm = ChatOpenAI(\n",
    "        model_name = \"gpt-3.5-turbo\",\n",
    "        temperature = 0.2,\n",
    "        max_tokens = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    output_key='answer',\n",
    "    memory_key='chat_history',\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_summarizer = OpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_template = \"\"\"You are a helpful assistant created to summarize conversations and text. Following there is a conversation and a context, \n",
    "you have to summarize the conversation in Spanish with a good summary and also summarize the context in Spanish and return a type of JSON response as\n",
    "chat_summary: your_chat_summary, context_summary:your_context_summary.\n",
    "    # Conversation: {messages}\n",
    "\n",
    "    # Context {context}\n",
    "    \n",
    "    # Your JSON response between curly brackets:\n",
    "    \"\"\"\n",
    "\n",
    "SUMMARY_TEMPLATE = PromptTemplate(\n",
    "    template=summary_template,\n",
    "    input_variables=[\"messages\", \"context\"]\n",
    ")\n",
    "\n",
    "summarizer_chain = LLMChain(llm=llm_summarizer, prompt=SUMMARY_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)\n",
    "\n",
    "template = \"\"\"Based on the context provided, provide an answer to the best of your knowledge.\n",
    "Use your skills to determine what kind of context is provided and tailor your response accordingly. \n",
    "When providing an answer, choose the tone of voice and humor of Zapp Brannigan from Futurama. Also, use html bullet list format when needed.\n",
    "Question: {question}\n",
    "=========\n",
    "{context}\n",
    "=========\n",
    "\"\"\"\n",
    "QA_PROMPT = PromptTemplate(template=template, input_variables=[\"question\", \"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- the world. >Since their introduction in 2017, Transformers have rapidly become the state-of-the-art approach to tackle tasks in many domains such as natural language processing, speech recognition, and computer vision. In short, if you’re doing deep learning, then you need Transformers! Lewis Tunstall, Hugging Face ML Engineer & Author of Natural Language Processing with Transformers Timeline of popular Transformer model releases: Source #### 2.4.1 How do Transformers work? Transformers work by leveraging attention, a powerful deep-learning algorithm, first seen in computer vision models. —Not all that different from how we humans process information through attention. We are incredibly good at forgetting/ignoring mundane daily inputs that don’t pose a threat or require a response from us. For example, can you remember everything you saw and heard coming home last Tuesday? Of course not! Our brain’s memory is limited and valuable. Our recall is aided by our ability to forget trivial inputs. Similarly, Machine Learning models need to learn how to pay attention only to the things that matter and not waste computational resources processing irrelevant information. Transformers create differential weights signaling which words in a sentence are the most critical to further process. A transformer does this by successively processing an input through a stack of transformer layers, usually called the encoder. If necessary, another stack of transformer layers - the decoder - can be used to predict a target output. —BERT however, doesn’t use a decoder. Transformers are uniquely\n",
      "- # Transformers State-of-the-art Machine Learning for [PyTorch]( [TensorFlow]( and [JAX]( Transformers provides APIs and tools to easily download and train state-of-the-art pretrained models. Using pretrained models can reduce your compute costs, carbon footprint, and save you the time and resources required to train a model from scratch. These models support common tasks in different modalities, such as: **Natural Language Processing**: text classification, named entity recognition, question answering, language modeling, summarization, translation, multiple choice, and text generation. **Computer Vision**: image classification, object detection, and segmentation. **Audio**: automatic speech recognition and audio classification. **Multimodal**: table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering. Transformers support framework interoperability between PyTorch, TensorFlow, and JAX. This provides the flexibility to use a different framework at each stage of a model's life; train a model in three lines of code in one framework, and load it for inference in another. Models can also be exported to a format like ONNX and TorchScript for deployment in production environments. Join the growing community on the [Hub]( [forum]( or [Discord]( today! ## If you are looking for custom support from the Hugging Face team ## Contents The documentation is organized into five sections: - **GET STARTED** provides a quick tour of the library and installation instructions to get up and running.\n",
      "- supported by Transformers. Each of these base classes are configurable, allowing you to use the specific attributes you want. You can easily setup a model for training or modify an existing pretrained model to fine-tune.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrieved = \"\"\n",
    "documents = retriever.get_relevant_documents(\"Que son transformers?\")\n",
    "for document in documents:\n",
    "    to_insert = \"- \" + document.page_content + '\\n'\n",
    "    retrieved += to_insert\n",
    "\n",
    "print(retrieved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = summarizer_chain.predict(messages =\"AI: Hola, estoy para ayudarte \\nUser: Quiero ayuda para una compra \\nAI: Claro que si\", context = retrieved)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "    \"chat_summary\": \"AI está aquí para ayudar al usuario con una compra.\",\n",
      "    \"context_summary\": \"Transformers es una herramienta de aprendizaje automático de vanguardia que se utiliza en una variedad de tareas en diferentes dominios, como el procesamiento del lenguaje natural, el reconocimiento de voz y la visión por computadora. Los Transformers funcionan mediante el uso de la atención, un algoritmo de aprendizaje profundo poderoso, y proporcionan una forma eficiente de entrenar modelos preentrenados para tareas comunes en diferentes modalidades. También ofrecen interoperabilidad entre diferentes frameworks y soporte para modelos personalizados.\" \n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationalRetrievalChain.from_llm(\n",
    "    llm = llm,\n",
    "    retriever = retriever,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "the world. >Since their introduction in 2017, Transformers have rapidly become the state-of-the-art approach to tackle tasks in many domains such as natural language processing, speech recognition, and computer vision. In short, if you’re doing deep learning, then you need Transformers! Lewis Tunstall, Hugging Face ML Engineer & Author of Natural Language Processing with Transformers Timeline of popular Transformer model releases: Source #### 2.4.1 How do Transformers work? Transformers work by leveraging attention, a powerful deep-learning algorithm, first seen in computer vision models. —Not all that different from how we humans process information through attention. We are incredibly good at forgetting/ignoring mundane daily inputs that don’t pose a threat or require a response from us. For example, can you remember everything you saw and heard coming home last Tuesday? Of course not! Our brain’s memory is limited and valuable. Our recall is aided by our ability to forget trivial inputs. Similarly, Machine Learning models need to learn how to pay attention only to the things that matter and not waste computational resources processing irrelevant information. Transformers create differential weights signaling which words in a sentence are the most critical to further process. A transformer does this by successively processing an input through a stack of transformer layers, usually called the encoder. If necessary, another stack of transformer layers - the decoder - can be used to predict a target output. —BERT however, doesn’t use a decoder. Transformers are uniquely\n",
      "\n",
      "# What Transformers can do Transformers is a library of pretrained state-of-the-art models for natural language processing (NLP), computer vision, and audio and speech processing tasks. Not only does the library contain Transformer models, but it also has non-Transformer models like modern convolutional networks for computer vision tasks. If you look at some of the most popular consumer products today, like smartphones, apps, and televisions, odds are that some kind of deep learning technology is behind it. Want to remove a background object from a picture taken by your smartphone? This is an example of a panoptic segmentation task (don't worry if you don't know what this means yet, we'll describe it in the following sections!). This page provides an overview of the different speech and audio, computer vision, and NLP tasks that can be solved with the Transformers library in just three lines of code! ## Audio Audio and speech processing tasks are a little different from the other modalities mainly because audio as an input is a continuous signal. Unlike text, a raw audio waveform can't be neatly split into discrete chunks the way a sentence can be divided into words. To get around this, the raw audio signal is typically sampled at regular intervals. If you take more samples within an interval, the sampling rate is higher, and the audio more closely resembles the original audio source. Previous approaches preprocessed the audio to extract useful features from it. It is now more common to start audio and speech processing tasks by directly feeding the raw audio waveform to a\n",
      "\n",
      "# Transformers State-of-the-art Machine Learning for [PyTorch]( [TensorFlow]( and [JAX]( Transformers provides APIs and tools to easily download and train state-of-the-art pretrained models. Using pretrained models can reduce your compute costs, carbon footprint, and save you the time and resources required to train a model from scratch. These models support common tasks in different modalities, such as: **Natural Language Processing**: text classification, named entity recognition, question answering, language modeling, summarization, translation, multiple choice, and text generation. **Computer Vision**: image classification, object detection, and segmentation. **Audio**: automatic speech recognition and audio classification. **Multimodal**: table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering. Transformers support framework interoperability between PyTorch, TensorFlow, and JAX. This provides the flexibility to use a different framework at each stage of a model's life; train a model in three lines of code in one framework, and load it for inference in another. Models can also be exported to a format like ONNX and TorchScript for deployment in production environments. Join the growing community on the [Hub]( [forum]( or [Discord]( today! ## If you are looking for custom support from the Hugging Face team ## Contents The documentation is organized into five sections: - **GET STARTED** provides a quick tour of the library and installation instructions to get up and running.\n",
      "Human: Que son los transformers?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "query = input(\"Entre su pregunta: \")\n",
    "result = conversation({\"question\":query, \"chat_history\":chat_history})\n",
    "chat_history.append((query, result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: Que son los transformers?\n",
      "Assistant: Los Transformers son un enfoque de vanguardia en el campo del aprendizaje profundo que se utiliza para abordar tareas en diversos dominios, como el procesamiento del lenguaje natural, el reconocimiento de voz y la visión por computadora. Son modelos de inteligencia artificial que utilizan un algoritmo llamado atención para procesar la información de manera eficiente. Los Transformers son ampliamente utilizados en aplicaciones de deep learning y han demostrado ser muy efectivos en una variedad de tareas.\n",
      "Human: Como los podria cargar y usar?\n",
      "Assistant: La forma de cargar y utilizar los Transformers es a través del uso de la biblioteca Transformers de Hugging Face. Puedes seguir una guía rápida para comenzar y aprender cómo usar el pipeline para inferencia, cargar un modelo pre-entrenado y un preprocesador con AutoClass, y entrenar rápidamente un modelo con PyTorch o TensorFlow.\n",
      "\n",
      "Para cargar y utilizar los Transformers, necesitarás instalar las bibliotecas necesarias, como Transformers y Datasets. También deberás instalar tu framework de aprendizaje automático preferido, ya sea PyTorch o TensorFlow.\n",
      "\n",
      "Una vez que hayas instalado las bibliotecas necesarias, puedes utilizar el pipeline para realizar inferencias con modelos pre-entrenados en diferentes tareas, como clasificación de texto, generación de texto, resumen de texto, entre otras. También puedes personalizar y configurar modelos base para entrenamiento o ajuste fino.\n",
      "\n",
      "Recuerda que Transformers es compatible con la interoperabilidad entre PyTorch, TensorFlow y JAX, lo que te permite utilizar diferentes frameworks en cada etapa del ciclo de vida de un modelo. Además, los modelos pueden exportarse a formatos como ONNX y TorchScript para su implementación en entornos de producción.\n",
      "\n",
      "Si necesitas soporte personalizado del equipo de Hugging Face, puedes unirte a la comunidad en el Hub, el foro o Discord.\n",
      "Human: Quiero que sepas que mi nombre es Jose\n",
      "Assistant: Soy un modelo de lenguaje desarrollado por OpenAI llamado GPT-3. No tengo un nombre propio, pero puedes llamarme \"Asistente\" si deseas. ¿En qué puedo ayudarte hoy?\n",
      "Follow Up Input: Quiero que me conozcas, me llamo Jose\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "Language Modeling]( 2020 - [6] : Asier Gutiérrez-Fandiño, Jordi Armengol-Estapé, et al., [MarIA: Spanish Language Models]( 2022 - [7] : Jack W. Rae, Sebastian Borgeaud, et al., [Scaling Language Models: Methods, Analysis & Insights from Training Gopher]( 2021 - [8] : Xi Victoria Lin, Todor Mihaylov, et al., [Few-shot Learning with Multilingual Language Models]( 2021 - [9] : Hugo Laurençon, Lucile Saulnier, et al., [The BigScience ROOTS Corpus: A 1.6TB Composite Multilingual Dataset]( 2022 - [10] : Daniel Fried, Armen Aghajanyan, et al., [InCoder: A Generative Model for Code Infilling and Synthesis]( 2022 - [11] : Erik Nijkamp, Bo Pang, et al., [CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis]( 2023 - [12] : Yujia Li, David Choi, et al., [Competition-Level Code Generation with AlphaCode]( 2022 - [13] : Frank F. Xu, Uri Alon, et al., [A Systematic Evaluation of Large Language Models of Code]( 2022 - [14] : Aakanksha Chowdhery, Sharan Narang, et al., [PaLM: Scaling Language Modeling with Pathways]( 2022 - [15] : Lewis Tunstall, Leandro von Werra, Thomas Wolf, [Natural Language Processing with Transformers, Revised Edition]( 2022 - [16] : Denis Kocetkov, Raymond Li, et al., [The Stack: 3 TB of permissively licensed source code]( 2022 - [17] : [Rocky | Project Hail Mary Wiki | Fandom]( - [18] : Raimondas Kiveris, Silvio Lattanzi, et al., [Connected Components in MapReduce and Beyond]( 2014 - [19] : Jacob Austin, Augustus Odena, et al., [Program Synthesis with Large Language Models]( 2021 - [20]: Amro Abbas, Kushal Tirumala, et al., [SemDeDup:\n",
      "\n",
      "--- title: \"Code Llama: Llama 2 learns to code\" thumbnail: /blog/assets/160_codellama/thumbnail.jpg authors: - user: philschmid - user: osanseviero - user: pcuenq - user: lewtun - user: lvwerra - user: loubnabnl - user: ArthurZ - user: joaogante --- # Code Llama: Llama 2 learns to code ## Introduction Code Llama is a family of state-of-the-art, open-access versions of [Llama 2]( specialized on code tasks, and we’re excited to release integration in the Hugging Face ecosystem! Code Llama has been released with the same permissive community license as Llama 2 and is available for commercial use. Today, we’re excited to release: - Models on the Hub with their model cards and license - Transformers integration - Integration with Text Generation Inference for fast and efficient production-ready inference - Integration with Inference Endpoints - Integration with VS Code extension - Code benchmarks Code LLMs are an exciting development for software engineers because they can boost productivity through code completion in IDEs, take care of repetitive or annoying tasks like writing docstrings, or create unit tests. ## Table of Contents - [Introduction](#introduction) - [Table of Contents](#table-of-contents) - [What’s Code Llama?](#whats-code-llama) - [How to use Code Llama?](#how-to-use-code-llama) - [Demo](#demo) - [Transformers](#transformers) - [A Note on dtypes](#a-note-on-dtypes) - [Code Completion](#code-completion) - [Code Infilling](#code-infilling) - [Conversational Instructions](#conversational-instructions) - [4-bit Loading](#4-bit-loading) - [Using\n",
      "\n",
      "the article (listed in alphabetical order): Britney Muller, Douwe Kiela, Jared Casper, Jeff Rasley, Julien Launay, Leandro von Werra, Omar Sanseviero, Stefan Schweter and Thomas Wang. The main graphics was created by Chunte Lee.\n",
      "Human: ¿Cómo te llamas?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Entre su pregunta: \")\n",
    "result = conversation({\"question\":query, \"chat_history\":chat_history})\n",
    "chat_history.append((query, result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n{\\n    \"chat_summary\": \"AI está aquí para ayudar al usuario con una compra.\",\\n    \"context_summary\": \"Transformers es una herramienta de aprendizaje automático de vanguardia que se utiliza en una variedad de tareas en diferentes dominios, como el procesamiento del lenguaje natural, el reconocimiento de voz y la visión por computadora. Los Transformers funcionan mediante el uso de la atención, un algoritmo de aprendizaje profundo poderoso, y proporcionan una forma eficiente de entrenar modelos preentrenados para tareas comunes en diferentes modalidades. También ofrecen interoperabilidad entre diferentes frameworks y soporte para modelos personalizados.\" \\n}'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface-chatbot-IRaqcdlO-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
